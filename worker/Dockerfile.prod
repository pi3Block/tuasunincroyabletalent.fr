# Worker Production Dockerfile - Celery + GPU
# Using PyTorch image (includes CUDA + PyTorch pre-installed = faster builds)
FROM pytorch/pytorch:2.5.1-cuda12.4-cudnn9-runtime

WORKDIR /app

# Install system dependencies + uv
RUN apt-get update && apt-get install -y \
    ffmpeg \
    git \
    libsndfile1 \
    curl \
    && rm -rf /var/lib/apt/lists/* \
    && curl -LsSf https://astral.sh/uv/install.sh | sh

# Add uv to PATH
ENV PATH="/root/.local/bin:$PATH"

# NOTE: GPU selection is handled by docker-compose device_ids, not CUDA_VISIBLE_DEVICES
# When Docker maps GPU 1 to the container, it becomes GPU 0 inside the container

# Install Python dependencies (PyTorch already included in base image)
COPY requirements.txt .
RUN --mount=type=cache,target=/root/.cache/uv \
    uv pip install --system -r requirements.txt

# Copy source (changes frequently)
COPY . .

# Default CMD - overridden by docker-compose command for each worker type
# worker-heavy: listens to gpu-heavy,gpu (priority tasks + fallback)
# worker-pool: listens to gpu only (standard GPU tasks)
# Using --pool=solo to avoid fork issues with CUDA (fork + CUDA = crash)
CMD ["celery", "-A", "tasks.celery_app", "worker", "--loglevel=info", "--pool=solo", "-Q", "gpu"]
